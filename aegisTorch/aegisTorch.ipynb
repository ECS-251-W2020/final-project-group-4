{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aegisTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FcmKGv8QFhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import Tensor\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfSXVOJxQJgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjNho1LZQLfl",
        "colab_type": "code",
        "outputId": "ff317eae-8b5d-4a57-8972-8a4fe07166ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtD0U_D5QS41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n",
        "net=CNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s87kZrlQTxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sS7L40aQVns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "net = net.cuda()\n",
        "net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cyDY2JNeCpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(dataset):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in dataset:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "  return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcQwBrL2QX68",
        "colab_type": "code",
        "outputId": "48faa855-ea05-4489-8975-30c1c8fed064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        }
      },
      "source": [
        "for epoch in range(0, 50):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # wrap them in Variable\n",
        "        #inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        if epoch > 16:\n",
        "            for group in optimizer.param_groups:\n",
        "                for p in group['params']:\n",
        "                    state = optimizer.state[p]\n",
        "                    if state['step'] >= 1024:\n",
        "                        state['step'] = 1000\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.data\n",
        "\n",
        "    # Normalizing the loss by the total number of train batches\n",
        "    running_loss /= len(trainloader)\n",
        "\n",
        "    # Calculate training/test set accuracy of the existing model\n",
        "    #train_accuracy = calculate_accuracy(trainloader)\n",
        "    #test_accuracy = calculate_accuracy(testloader)\n",
        "\n",
        "    print(\"Iteration: {0} | Loss: {1} |\".format(epoch+1, running_loss))\n",
        "\n",
        "    # save model  Training accuracy: {2}% | Test accuracy: {3}% , train_accuracy, test_accuracy\n",
        "    #if epoch % 50 == 0:\n",
        "    #    print('==> Saving model ...')\n",
        "     #   state = {\n",
        "      #      'net': net.module,\n",
        "       #     'epoch': epoch,\n",
        "        #}\n",
        "        #if not os.path.isdir('checkpoint'):\n",
        "         #   os.mkdir('checkpoint')\n",
        "        #torch.save(state, '../checkpoint/ckpt.t7')\n",
        "\n",
        "print('==> Finished Training ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 | Loss: 0.7786043286323547 |\n",
            "Iteration: 2 | Loss: 0.7056595683097839 |\n",
            "Iteration: 3 | Loss: 0.6485595107078552 |\n",
            "Iteration: 4 | Loss: 0.6013839840888977 |\n",
            "Iteration: 5 | Loss: 0.5600818991661072 |\n",
            "Iteration: 6 | Loss: 0.5246593952178955 |\n",
            "Iteration: 7 | Loss: 0.4968425929546356 |\n",
            "Iteration: 8 | Loss: 0.4686832129955292 |\n",
            "Iteration: 9 | Loss: 0.44329696893692017 |\n",
            "Iteration: 10 | Loss: 0.4183397889137268 |\n",
            "Iteration: 11 | Loss: 0.3966088593006134 |\n",
            "Iteration: 12 | Loss: 0.3834694027900696 |\n",
            "Iteration: 13 | Loss: 0.3653469979763031 |\n",
            "Iteration: 14 | Loss: 0.343368262052536 |\n",
            "Iteration: 15 | Loss: 0.3315315842628479 |\n",
            "Iteration: 16 | Loss: 0.31881919503211975 |\n",
            "Iteration: 17 | Loss: 0.3027816116809845 |\n",
            "Iteration: 18 | Loss: 0.27673643827438354 |\n",
            "Iteration: 19 | Loss: 0.26327747106552124 |\n",
            "Iteration: 20 | Loss: 0.2570335566997528 |\n",
            "Iteration: 21 | Loss: 0.24076591432094574 |\n",
            "Iteration: 22 | Loss: 0.2320958822965622 |\n",
            "Iteration: 23 | Loss: 0.2246130406856537 |\n",
            "Iteration: 24 | Loss: 0.21502509713172913 |\n",
            "Iteration: 25 | Loss: 0.20830102264881134 |\n",
            "Iteration: 26 | Loss: 0.19873443245887756 |\n",
            "Iteration: 27 | Loss: 0.19249819219112396 |\n",
            "Iteration: 28 | Loss: 0.1898382604122162 |\n",
            "Iteration: 29 | Loss: 0.17588262259960175 |\n",
            "Iteration: 30 | Loss: 0.16988670825958252 |\n",
            "Iteration: 31 | Loss: 0.16783608496189117 |\n",
            "Iteration: 32 | Loss: 0.16010263562202454 |\n",
            "Iteration: 33 | Loss: 0.1566014587879181 |\n",
            "Iteration: 34 | Loss: 0.14877332746982574 |\n",
            "Iteration: 35 | Loss: 0.14433003962039948 |\n",
            "Iteration: 36 | Loss: 0.13885539770126343 |\n",
            "Iteration: 37 | Loss: 0.13173536956310272 |\n",
            "Iteration: 38 | Loss: 0.1312866061925888 |\n",
            "Iteration: 39 | Loss: 0.12382542341947556 |\n",
            "Iteration: 40 | Loss: 0.1220841258764267 |\n",
            "Iteration: 41 | Loss: 0.1199498176574707 |\n",
            "Iteration: 42 | Loss: 0.11291442066431046 |\n",
            "Iteration: 43 | Loss: 0.11305686831474304 |\n",
            "Iteration: 44 | Loss: 0.10495232045650482 |\n",
            "Iteration: 45 | Loss: 0.10867805778980255 |\n",
            "Iteration: 46 | Loss: 0.10211925953626633 |\n",
            "Iteration: 47 | Loss: 0.0982385203242302 |\n",
            "Iteration: 48 | Loss: 0.09677588194608688 |\n",
            "Iteration: 49 | Loss: 0.09331651031970978 |\n",
            "Iteration: 50 | Loss: 0.0906691774725914 |\n",
            "==> Finished Training ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ssC5ccvQavW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}